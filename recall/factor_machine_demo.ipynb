{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FM模型TensorFlow2.X构建\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import os\n",
    "\n",
    "# All the data could be downloaded from: https://www.kaggle.com/datasets/mrkmakr/criteo-dataset\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "criteo数据集预处理\n",
    "\n",
    "criteo数据特征说明：\n",
    "- Label - 标签列，「点击」取值为1，「未点击」取值为0\n",
    "- I1-I13 - 总共13列整型特征（绝大多数是计数特征）\n",
    "- C1-C26 - 总共26列类别型特征，基于脱敏原因，数据经过哈希处理得到32位串\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sparse_feature(feat, feat_num, embed_dim=4):\n",
    "    \"\"\"\n",
    "    为稀疏特征构建字典\n",
    "    :@param feat: 特征名称\n",
    "    :@param feat_num: 不重复的稀疏特征个数\n",
    "    :@param embed_dim: 特征嵌入(embedding)的维度\n",
    "    \"\"\"\n",
    "    return {'feat_name': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n",
    "\n",
    "\n",
    "def dense_feature(feat):\n",
    "    \"\"\"\n",
    "    为稠密(数值)型特征构建字典\n",
    "    :@param feat: 特征名称\n",
    "    \"\"\"\n",
    "    return {'feat_name': feat}\n",
    "\n",
    "\n",
    "def create_criteo_dataset(file, embed_dim=8, read_part=True, sample_num=100000, test_size=0.2):\n",
    "    \"\"\"\n",
    "    criteo数据集预处理\n",
    "    :@param file: 数据路径\n",
    "    :@param embed_dim: 稀疏特征的嵌入(embedding)维度\n",
    "    :@param read_part: 读取部分数据(在数据集很大的情况下最好设定为True)\n",
    "    :@param sample_num: 部分读取的形态下，每个part的样本量\n",
    "    :@param test_size: 测试集比例\n",
    "    \"\"\"\n",
    "    names = ['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13',\n",
    "             'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
    "             'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22',\n",
    "             'C23', 'C24', 'C25', 'C26']\n",
    "\n",
    "    # 部分读取与全部读取\n",
    "    if read_part:\n",
    "        data_df = pd.read_csv(file, sep='\\t', iterator=True, header=None, names=names)\n",
    "        data_df = data_df.get_chunk(sample_num)\n",
    "\n",
    "    else:\n",
    "        data_df = pd.read_csv(file, sep='\\t', header=None, names=names)\n",
    "\n",
    "    # 指定稀疏特征与稠密特征\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "    features = sparse_features + dense_features\n",
    "\n",
    "    # 缺失值填充\n",
    "    data_df[sparse_features] = data_df[sparse_features].fillna('nan')\n",
    "    data_df[dense_features] = data_df[dense_features].fillna(0)\n",
    "\n",
    "    # 离散化处理\n",
    "    est = KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='uniform')\n",
    "    data_df[dense_features] = est.fit_transform(data_df[dense_features])\n",
    "\n",
    "    for feat in sparse_features:\n",
    "        le = LabelEncoder()\n",
    "        data_df[feat] = le.fit_transform(data_df[feat])\n",
    "\n",
    "    # 特征工程：对离散特征进行embedding处理\n",
    "    feature_columns = [sparse_feature(feat, int(data_df[feat].max()) + 1, embed_dim=embed_dim) for feat in features]\n",
    "    train, test = train_test_split(data_df, test_size=test_size)\n",
    "\n",
    "    # 生成训练与测试集\n",
    "    train_X = train[features].values.astype('int32')\n",
    "    train_y = train['label'].values.astype('int32')\n",
    "    test_X = test[features].values.astype('int32')\n",
    "    test_y = test['label'].values.astype('int32')\n",
    "\n",
    "    return feature_columns, (train_X, train_y), (test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "    def __init__(self, feature_columns, k, w_r=1e-6, v_r=1e-6):\n",
    "        \"\"\"\n",
    "        FM模型\n",
    "        :@param feature_columns: A list. sparse column feature information.\n",
    "        :@param k: 隐向量维度\n",
    "        :@param w_r: 参数w的正则化系数\n",
    "        :@param v_r: 参数v的正则化系数\n",
    "        \"\"\"\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.sparse_feature_columns = feature_columns\n",
    "        self.index_mapping = []\n",
    "        self.feature_length = 0\n",
    "        for feat in self.sparse_feature_columns:\n",
    "            self.index_mapping.append(self.feature_length)\n",
    "            self.feature_length += feat['feat_num']\n",
    "        self.k = k\n",
    "        self.w_r = w_r\n",
    "        self.v_r = v_r\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w0 = self.add_weight(name='w0', shape=(1,),\n",
    "                                  initializer=tf.zeros_initializer(),\n",
    "                                  trainable=True)\n",
    "        self.w = self.add_weight(name='w', shape=(self.feature_length, 1),\n",
    "                                 initializer=tf.random_normal_initializer(),\n",
    "                                 regularizer=l2(self.w_r),\n",
    "                                 trainable=True)\n",
    "        self.V = self.add_weight(name='V', shape=(self.feature_length, self.k),\n",
    "                                 initializer=tf.random_normal_initializer(),\n",
    "                                 regularizer=l2(self.v_r),\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # 映射\n",
    "        inputs = inputs + tf.convert_to_tensor(self.index_mapping)\n",
    "        \n",
    "        # 一阶项\n",
    "        first_order = self.w0 + tf.reduce_sum(tf.nn.embedding_lookup(self.w, inputs), axis=1)  # (batch_size, 1)\n",
    "        \n",
    "        # 二阶项\n",
    "        second_inputs = tf.nn.embedding_lookup(self.V, inputs)  # (batch_size, fields, embed_dim)\n",
    "        square_sum = tf.square(tf.reduce_sum(second_inputs, axis=1, keepdims=True))  # (batch_size, 1, embed_dim)\n",
    "        sum_square = tf.reduce_sum(tf.square(second_inputs), axis=1, keepdims=True)  # (batch_size, 1, embed_dim)\n",
    "        second_order = 0.5 * tf.reduce_sum(square_sum - sum_square, axis=2)  # (batch_size, 1)\n",
    "        \n",
    "        # 一阶+二阶\n",
    "        outputs = first_order + second_order\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Model):\n",
    "    def __init__(self, feature_columns, k, w_r=1e-6, v_r=1e-6):\n",
    "        \"\"\"\n",
    "        Factorization Machines\n",
    "        :param feature_columns: A list. sparse column feature information.\n",
    "        :param k: the latent vector\n",
    "        :param w_r: the regularization coefficient of parameter w\n",
    "\t\t:param v_r: the regularization coefficient of parameter v\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.sparse_feature_columns = feature_columns\n",
    "        self.fm = MyLayer(feature_columns, k, w_r, v_r)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        fm_outputs = self.fm(inputs)\n",
    "        outputs = tf.nn.sigmoid(fm_outputs)\n",
    "        return outputs\n",
    "\n",
    "    def summary(self, **kwargs):\n",
    "        sparse_inputs = Input(shape=(len(self.sparse_feature_columns),), dtype=tf.int32)\n",
    "        Model(inputs=sparse_inputs, outputs=self.call(sparse_inputs)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境设定\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#フォルダ\n",
    "dataDir = '/Users/hayden/Documents/data'#フォルダ\n",
    "\n",
    "# 超参数设定\n",
    "file = dataDir + '/Criteo_dataset/train.txt'\n",
    "read_part = True\n",
    "sample_num = 200000\n",
    "test_size = 0.2\n",
    "\n",
    "k = 8\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 512\n",
    "epochs = 10\n",
    "\n",
    "# 构建数据集\n",
    "feature_columns, train, test = create_criteo_dataset(file=file,\n",
    "                                        read_part=read_part,\n",
    "                                        sample_num=sample_num,\n",
    "                                        test_size=test_size)\n",
    "train_X, train_y = train\n",
    "test_X, test_y = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 39)]              0         \n",
      "                                                                 \n",
      " my_layer (MyLayer)          (None, 1)                 3751795   \n",
      "                                                                 \n",
      " tf.math.sigmoid (TFOpLambd  (None, 1)                 0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3751795 (14.31 MB)\n",
      "Trainable params: 3751795 (14.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 21:49:21.413246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - ETA: 0s - loss: 0.5057 - auc: 0.7128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 21:49:28.052561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 7s 19ms/step - loss: 0.5057 - auc: 0.7128 - val_loss: 0.4688 - val_auc: 0.7635\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.4063 - auc: 0.8444 - val_loss: 0.4698 - val_auc: 0.7666\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.3262 - auc: 0.9088 - val_loss: 0.4925 - val_auc: 0.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a82a9900>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 模型构建\n",
    "model = FM(feature_columns=feature_columns, k=k)\n",
    "model.summary()\n",
    "model.compile(loss=binary_crossentropy, \n",
    "                optimizer=Adam(learning_rate=learning_rate),\n",
    "                metrics=[AUC()])\n",
    "\n",
    "# 模型训练\n",
    "model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)],  # checkpoint\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.15\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 11ms/step - loss: 0.4743 - auc: 0.7607\n",
      "test AUC: 0.760714\n"
     ]
    }
   ],
   "source": [
    "# 测试集上验证效果\n",
    "print('test AUC: %f' % model.evaluate(test_X, test_y, batch_size=batch_size)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   12,   118, 83059, ...,     1,     0,     0],\n",
       "       [  148,    62, 62800, ...,    12,     0,     0],\n",
       "       [   12,   296, 10578, ...,     6,     0,     0],\n",
       "       ...,\n",
       "       [  301,   118, 68646, ...,     2,     0,     0],\n",
       "       [   12,   443, 56302, ...,     0,     0,     0],\n",
       "       [   12,   487, 35936, ...,     3,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 39)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(40000, 39)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_layer/V:0' shape=(416866, 8) dtype=float32, numpy=\n",
       "array([[-0.07061051,  0.03911226,  0.00684353, ..., -0.02671424,\n",
       "         0.0013881 ,  0.08055133],\n",
       "       [ 0.01250868, -0.01755876,  0.01218676, ..., -0.02601379,\n",
       "         0.01278361, -0.03148063],\n",
       "       [ 0.04311165,  0.01400692,  0.00356985, ...,  0.00036511,\n",
       "         0.00878077,  0.04960729],\n",
       "       ...,\n",
       "       [ 0.07237215,  0.0586164 , -0.050928  , ...,  0.00987792,\n",
       "        -0.04890952, -0.01900741],\n",
       "       [ 0.00903635, -0.00232638,  0.00441977, ..., -0.00183274,\n",
       "        -0.00590627, -0.00448157],\n",
       "       [-0.03557094,  0.04855461, -0.03319177, ...,  0.07543939,\n",
       "         0.01555497, -0.00623946]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fm.V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_layer/w:0' shape=(416866, 1) dtype=float32, numpy=\n",
       "array([[ 0.06552668],\n",
       "       [-0.04119697],\n",
       "       [ 0.05113696],\n",
       "       ...,\n",
       "       [ 0.00861098],\n",
       "       [-0.02402387],\n",
       "       [-0.03423011]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fm.w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
